      # 4. Generate RSS feed from Reuters JSON API
      - name: Generate RSS feed
        run: |
          python << 'EOF'
          import requests
          from feedgen.feed import FeedGenerator
          from dateutil.parser import parse
          import datetime
          import os
          import xml.etree.ElementTree as ET

          feed_file = 'feed.xml'
          max_items = 50

          fg = FeedGenerator()
          fg.title('Reuters Technology RSS')
          fg.link(href='https://rebus77.github.io/r_tech/')
          fg.description('RSS feed for Reuters Technology news')

          # Load existing feed items
          existing_items = []
          if os.path.exists(feed_file):
              tree = ET.parse(feed_file)
              root = tree.getroot()
              for item in root.findall('channel/item'):
                  existing_items.append({
                      'title': item.find('title').text,
                      'link': item.find('link').text,
                      'description': item.find('description').text if item.find('description') is not None else '',
                      'pubDate': item.find('pubDate').text
                  })

          # Fetch articles from Reuters JSON API
          url = 'https://www.reuters.com/pf/api/v3/content/fetch/articles-by-section?section=technology&limit=15'
          headers = {'User-Agent': 'Mozilla/5.0'}
          r = requests.get(url, headers=headers)
          r.raise_for_status()
          data = r.json()

          new_articles = []
          for item in data.get('result', {}).get('articles', []):
              title = item.get('title')
              link = 'https://www.reuters.com' + item.get('canonicalUrl', '')
              description = item.get('summary', '')
              pub_dt = parse(item.get('publishedTime')).strftime("%a, %d %b %Y %H:%M:%S %z") if item.get('publishedTime') else datetime.datetime.utcnow().strftime("%a, %d %b %Y %H:%M:%S +0000")
              new_articles.append({
                  'title': title,
                  'link': link,
                  'description': description,
                  'pubDate': pub_dt
              })

          # Merge with existing, remove duplicates
          combined = new_articles + [x for x in existing_items if x['link'] not in {a['link'] for a in new_articles}]
          combined = combined[:max_items]

          # Add items to feed
          for article in combined:
              fe = fg.add_entry()
              fe.id(article['link'])
              fe.link(href=article['link'])
              fe.title(article['title'])
              fe.description(article['description'])
              fe.pubDate(article['pubDate'])

          # Add timestamp entry for feed update
          timestamp_entry = fg.add_entry()
          timestamp_entry.id('feed-update-time')
          timestamp_entry.title('Feed last updated')
          timestamp_entry.description(f'RSS feed updated at {datetime.datetime.utcnow().strftime("%Y-%m-%d %H:%M:%S UTC")}')
          timestamp_entry.pubDate(datetime.datetime.utcnow().strftime("%a, %d %b %Y %H:%M:%S +0000"))

          # Write feed
          fg.rss_file(feed_file)
          EOF
